{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macOS-13.2.1-arm64-arm-64bit\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "from IPython.display import clear_output\n",
    "print(platform.platform())\n",
    "\n",
    "def resolve_dir(Dir):\n",
    "    if not os.path.exists(Dir):\n",
    "        os.mkdir(Dir)\n",
    "\n",
    "def reset_path(Dir):\n",
    "    if not os.path.exists(Dir):\n",
    "        os.mkdir(Dir)\n",
    "    else:\n",
    "        os.system('rm -f {}/*'.format( Dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n",
      "Tensorflow version 2.13.0-rc2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(73)\n",
    "TPU_INIT = False\n",
    "\n",
    "if TPU_INIT:\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    \n",
    "    except ValueError:\n",
    "        raise BaseException('ERROR: Not connected to a TPU runtime!')\n",
    "else:\n",
    "    !nvidia-smi\n",
    ";    \n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import imageio\n",
    "import imgaug.augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "IMG_SIZE = 128\n",
    "ColorChannels = 3\n",
    "\n",
    "def video_to_frames(video):\n",
    "    vidcap = cv2.VideoCapture(video)\n",
    "    \n",
    "    import math\n",
    "    rate = math.floor(vidcap.get(3))\n",
    "    count = 0\n",
    "    \n",
    "    ImageFrames = []\n",
    "    while vidcap.isOpened():\n",
    "        ID = vidcap.get(1)\n",
    "        success, image = vidcap.read()\n",
    "        \n",
    "        if success:\n",
    "            if (ID % 7 == 0):\n",
    "                flip = iaa.Fliplr(1.0)\n",
    "                zoom = iaa.Affine(scale=1.3)\n",
    "                random_brightness = iaa.Multiply((1, 1.3))\n",
    "                rotate = iaa.Affine(rotate=(-25, 25))\n",
    "                \n",
    "                image_aug = flip(image = image)\n",
    "                image_aug = random_brightness(image = image_aug)\n",
    "                image_aug = zoom(image = image_aug)\n",
    "                image_aug = rotate(image = image_aug)\n",
    "                \n",
    "                rgb_img = cv2.cvtColor(image_aug, cv2.COLOR_BGR2RGB)\n",
    "                resized = cv2.resize(rgb_img, (IMG_SIZE, IMG_SIZE))\n",
    "                ImageFrames.append(resized)\n",
    "            count+=1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    vidcap.release()\n",
    "    \n",
    "    return ImageFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have \n",
      "1000 Violence videos \n",
      "1000 NonViolence videos\n"
     ]
    }
   ],
   "source": [
    "print('we have \\n{} Violence videos \\n{} NonViolence videos'.format(\n",
    "              len(os.listdir('/Users/faizahkureshi/Desktop/GAIP Project/violencedataset/NonViolence')), \n",
    "              len(os.listdir('/Users/faizahkureshi/Desktop/GAIP Project/violencedataset/NonViolence'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have \n",
      "1000 Violence videos \n",
      "1000 NonViolence videos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 350/350 [00:18<00:00, 18.70it/s]\n",
      "100%|██████████| 350/350 [00:46<00:00,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 5.22 s, total: 2min 50s\n",
      "Wall time: 1min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#tqdm is used here to visulaize the progress of dataset creation\n",
    "from tqdm import tqdm\n",
    "\n",
    "VideoDataDir ='/Users/faizahkureshi/Desktop/GAIP Project/violencedataset'\n",
    "print('we have \\n{} Violence videos \\n{} NonViolence videos'.format(\n",
    "              len(os.listdir('/Users/faizahkureshi/Desktop/GAIP Project/violencedataset/NonViolence')), \n",
    "              len(os.listdir('/Users/faizahkureshi/Desktop/GAIP Project/violencedataset/NonViolence'))))\n",
    "\n",
    "X_original = []\n",
    "y_original = []\n",
    "CLASSES = [\"NonViolence\", \"Violence\"]\n",
    "\n",
    "for category in os.listdir(VideoDataDir):\n",
    "    category_path = os.path.join(VideoDataDir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        class_num = CLASSES.index(category)\n",
    "        try:\n",
    "            video_list = [video for video in os.listdir(category_path)[:350] if video != '.DS_Store']\n",
    "            for i, video in enumerate(tqdm(video_list)):\n",
    "                video_path = os.path.join(category_path, video)\n",
    "                frames = video_to_frames(video_path)\n",
    "                for j, frame in enumerate(frames):\n",
    "                    X_original.append(frame)\n",
    "                    y_original.append(class_num)\n",
    "        except OSError as e:\n",
    "            print(f\"Error processing directory: {category_path}. Skipping...\")\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13487"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_original = np.array(X_original).reshape(-1 , IMG_SIZE * IMG_SIZE * 3)\n",
    "y_original = np.array(y_original)\n",
    "len(X_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13487"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "stratified_sample = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=73)\n",
    "\n",
    "for train_index, test_index in stratified_sample.split(X_original, y_original):\n",
    "    X_train, X_test = X_original[train_index], X_original[test_index]\n",
    "    y_train, y_test = y_original[train_index], y_original[test_index]\n",
    "\n",
    "X_train_nn = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
    "X_test_nn = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4047"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9440"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4047"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9440"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set the input shape\n",
    "input_shape = (128, 128, 3)\n",
    "\n",
    "\n",
    "# Create the base ResNet50 model\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "\n",
    "# Freeze the base model's layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the custom head for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='selu', kernel_regularizer=l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='selu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "295/295 [==============================] - 153s 515ms/step - loss: 1.8777 - accuracy: 0.7002 - val_loss: 1.2113 - val_accuracy: 0.6943\n",
      "Epoch 2/50\n",
      "295/295 [==============================] - 147s 500ms/step - loss: 0.9654 - accuracy: 0.7514 - val_loss: 0.8161 - val_accuracy: 0.7759\n",
      "Epoch 3/50\n",
      "295/295 [==============================] - 149s 504ms/step - loss: 0.7620 - accuracy: 0.7606 - val_loss: 0.7420 - val_accuracy: 0.7361\n",
      "Epoch 4/50\n",
      "295/295 [==============================] - 149s 507ms/step - loss: 0.6955 - accuracy: 0.7673 - val_loss: 0.6893 - val_accuracy: 0.7576\n",
      "Epoch 5/50\n",
      "295/295 [==============================] - 154s 523ms/step - loss: 0.6528 - accuracy: 0.7675 - val_loss: 0.6419 - val_accuracy: 0.7700\n",
      "Epoch 6/50\n",
      "295/295 [==============================] - 141s 477ms/step - loss: 0.6225 - accuracy: 0.7788 - val_loss: 0.6834 - val_accuracy: 0.7257\n",
      "Epoch 7/50\n",
      "295/295 [==============================] - 140s 475ms/step - loss: 0.6024 - accuracy: 0.7854 - val_loss: 0.6582 - val_accuracy: 0.7559\n",
      "Epoch 8/50\n",
      "295/295 [==============================] - 140s 474ms/step - loss: 0.6041 - accuracy: 0.7887 - val_loss: 0.6839 - val_accuracy: 0.7457\n",
      "Epoch 9/50\n",
      "295/295 [==============================] - 143s 486ms/step - loss: 0.5839 - accuracy: 0.7925 - val_loss: 0.6392 - val_accuracy: 0.7685\n",
      "Epoch 10/50\n",
      "295/295 [==============================] - 150s 510ms/step - loss: 0.5724 - accuracy: 0.8054 - val_loss: 0.6296 - val_accuracy: 0.7751\n",
      "Epoch 11/50\n",
      "295/295 [==============================] - 148s 502ms/step - loss: 0.5542 - accuracy: 0.8089 - val_loss: 0.6177 - val_accuracy: 0.7751\n",
      "Epoch 12/50\n",
      "295/295 [==============================] - 145s 492ms/step - loss: 0.5583 - accuracy: 0.8090 - val_loss: 0.7021 - val_accuracy: 0.7564\n",
      "Epoch 13/50\n",
      "295/295 [==============================] - 140s 476ms/step - loss: 0.5509 - accuracy: 0.8095 - val_loss: 0.6510 - val_accuracy: 0.7517\n",
      "Epoch 14/50\n",
      "295/295 [==============================] - 143s 486ms/step - loss: 0.5277 - accuracy: 0.8258 - val_loss: 0.5896 - val_accuracy: 0.7944\n",
      "Epoch 15/50\n",
      "295/295 [==============================] - 146s 496ms/step - loss: 0.5215 - accuracy: 0.8274 - val_loss: 0.6258 - val_accuracy: 0.7840\n",
      "Epoch 16/50\n",
      "295/295 [==============================] - 148s 501ms/step - loss: 0.5227 - accuracy: 0.8234 - val_loss: 0.6023 - val_accuracy: 0.7895\n",
      "Epoch 17/50\n",
      "295/295 [==============================] - 151s 511ms/step - loss: 0.5158 - accuracy: 0.8285 - val_loss: 0.6068 - val_accuracy: 0.7905\n",
      "Epoch 18/50\n",
      "295/295 [==============================] - 152s 517ms/step - loss: 0.4984 - accuracy: 0.8353 - val_loss: 0.6016 - val_accuracy: 0.7922\n",
      "Epoch 19/50\n",
      "295/295 [==============================] - 150s 508ms/step - loss: 0.4931 - accuracy: 0.8394 - val_loss: 0.6051 - val_accuracy: 0.7949\n",
      "Epoch 20/50\n",
      "295/295 [==============================] - 155s 525ms/step - loss: 0.4899 - accuracy: 0.8363 - val_loss: 0.6224 - val_accuracy: 0.7868\n",
      "Epoch 21/50\n",
      "295/295 [==============================] - 166s 563ms/step - loss: 0.4817 - accuracy: 0.8408 - val_loss: 0.6220 - val_accuracy: 0.7944\n",
      "Epoch 22/50\n",
      "295/295 [==============================] - 155s 527ms/step - loss: 0.4732 - accuracy: 0.8450 - val_loss: 0.6155 - val_accuracy: 0.7695\n",
      "Epoch 23/50\n",
      "295/295 [==============================] - 157s 532ms/step - loss: 0.4576 - accuracy: 0.8487 - val_loss: 0.5767 - val_accuracy: 0.7974\n",
      "Epoch 24/50\n",
      "295/295 [==============================] - 147s 499ms/step - loss: 0.4710 - accuracy: 0.8411 - val_loss: 0.5777 - val_accuracy: 0.8043\n",
      "Epoch 25/50\n",
      "295/295 [==============================] - 159s 539ms/step - loss: 0.4514 - accuracy: 0.8520 - val_loss: 0.6161 - val_accuracy: 0.7932\n",
      "Epoch 26/50\n",
      "295/295 [==============================] - 167s 565ms/step - loss: 0.4423 - accuracy: 0.8571 - val_loss: 0.5502 - val_accuracy: 0.8117\n",
      "Epoch 27/50\n",
      "295/295 [==============================] - 153s 519ms/step - loss: 0.4486 - accuracy: 0.8532 - val_loss: 0.6069 - val_accuracy: 0.7964\n",
      "Epoch 28/50\n",
      "295/295 [==============================] - 151s 514ms/step - loss: 0.4408 - accuracy: 0.8571 - val_loss: 0.6078 - val_accuracy: 0.7944\n",
      "Epoch 29/50\n",
      "295/295 [==============================] - 153s 520ms/step - loss: 0.4417 - accuracy: 0.8543 - val_loss: 0.6180 - val_accuracy: 0.7961\n",
      "Epoch 30/50\n",
      "295/295 [==============================] - 237s 804ms/step - loss: 0.4425 - accuracy: 0.8562 - val_loss: 0.5631 - val_accuracy: 0.8120\n",
      "Epoch 31/50\n",
      "295/295 [==============================] - 337s 1s/step - loss: 0.4359 - accuracy: 0.8592 - val_loss: 0.5924 - val_accuracy: 0.7919\n",
      "Epoch 32/50\n",
      "295/295 [==============================] - 329s 1s/step - loss: 0.4265 - accuracy: 0.8632 - val_loss: 0.6197 - val_accuracy: 0.7932\n",
      "Epoch 33/50\n",
      "295/295 [==============================] - 321s 1s/step - loss: 0.4273 - accuracy: 0.8625 - val_loss: 0.6419 - val_accuracy: 0.7811\n",
      "Epoch 34/50\n",
      "227/295 [======================>.......] - ETA: 54s - loss: 0.4258 - accuracy: 0.8627"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_nn, y_train, batch_size=32, epochs=50, validation_data=(X_test_nn, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mX_test_nn\u001b[49m, y_test)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, accuracy)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_nn' is not defined"
     ]
    }
   ],
   "source": [
    "          \n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_nn, y_test)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('/Users/faizahkureshi/Desktop/GAIP Project/modelnew.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Assuming you have the predicted probabilities and true labels for both models\n",
    "# pred_prob_model1: predicted probabilities for model 1\n",
    "# true_labels: true labels\n",
    "\n",
    "# Calculate the false positive rate (fpr) and true positive rate (tpr) for model 1\n",
    "fpr_model1, tpr_model1, _ = roc_curve(true_labels, pred_prob_model1)\n",
    "\n",
    "# Calculate the false positive rate (fpr) and true positive rate (tpr) for model 2\n",
    "fpr_model2, tpr_model2, _ = roc_curve(true_labels, pred_prob_model2)\n",
    "\n",
    "# Calculate the area under the ROC curve (AUC) for both models\n",
    "auc_model1 = roc_auc_score(true_labels, pred_prob_model1)\n",
    "auc_model2 = roc_auc_score(true_labels, pred_prob_model2)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr_model1, tpr_model1, label='Model 1 (AUC = {:.2f})'.format(auc_model1))\n",
    "plt.plot(fpr_model2, tpr_model2, label='Model 2 (AUC = {:.2f})'.format(auc_model2))\n",
    "\n",
    "# Set labels and title for the plot\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming you have the true labels and predicted labels stored in variables\n",
    "true_labels =y_test\n",
    "predicted_labels = predictions\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
